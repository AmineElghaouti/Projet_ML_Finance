{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "v4c_5o0Ah9rT",
      "metadata": {
        "id": "v4c_5o0Ah9rT"
      },
      "source": [
        "***2. Régression Logistique Binomiale***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "======================================================================"
      ],
      "metadata": {
        "id": "0lVmUWJBhCkZ"
      },
      "id": "0lVmUWJBhCkZ"
    },
    {
      "cell_type": "code",
      "source": [
        "distress_label = label_encoder.transform(['DISTRESS'])[0]\n",
        "high_label = label_encoder.transform(['HIGH'])[0]\n",
        "\n",
        "y_train_binary = ((y_train_final == distress_label) | (y_train_final == high_label)).astype(int)\n",
        "y_test_binary = ((y_test_final == distress_label) | (y_test_final == high_label)).astype(int)\n",
        "\n",
        "ratio = (~y_train_binary.astype(bool)).sum() / y_train_binary.sum()\n",
        "\n",
        "cost_fn = 10\n",
        "cost_fp = 1\n",
        "\n",
        "n_at_risque = y_train_binary.sum()\n",
        "n_soutenable = (~y_train_binary.astype(bool)).sum()\n",
        "n_total = len(y_train_binary)\n",
        "\n",
        "weight_at_risque = (cost_fn / (cost_fn + cost_fp)) * (n_total / n_at_risque)\n",
        "weight_soutenable = (cost_fp / (cost_fn + cost_fp)) * (n_total / n_soutenable)\n",
        "\n",
        "total_weight = weight_at_risque + weight_soutenable\n",
        "weight_at_risque = weight_at_risque / (total_weight / 2)\n",
        "weight_soutenable = weight_soutenable / (total_weight / 2)\n",
        "\n",
        "class_weight_custom = {1: weight_at_risque, 0: weight_soutenable}\n",
        "\n",
        "def cost_sensitive_score(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    if cm.shape == (2, 2):\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "    else:\n",
        "        return 0\n",
        "    total_cost = fn * cost_fn + fp * cost_fp\n",
        "    max_cost = len(y_true) * max(cost_fn, cost_fp)\n",
        "    return 1 - (total_cost / max_cost)\n",
        "\n",
        "cost_scorer = make_scorer(cost_sensitive_score)\n",
        "\n",
        "\n",
        "search_spaces_binary = {\n",
        "    'C': Real(0.001, 100, prior='log-uniform'),\n",
        "    'penalty': Categorical(['l1', 'l2', 'elasticnet']),\n",
        "    'l1_ratio': Real(0.0, 1.0),\n",
        "    'solver': Categorical(['saga']),\n",
        "    'max_iter': Integer(200, 2000),\n",
        "}\n",
        "\n",
        "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "model_balanced = LogisticRegression(\n",
        "    random_state=42,\n",
        "    warm_start=True,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "\n",
        "bayes_search_balanced = BayesSearchCV(\n",
        "    estimator=model_balanced,\n",
        "    search_spaces=search_spaces_binary,\n",
        "    n_iter=30,\n",
        "    cv=cv_strategy,\n",
        "    scoring=cost_scorer,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=0,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "bayes_search_balanced.fit(X_train_final, y_train_binary)\n",
        "\n",
        "cv_results_balanced = pd.DataFrame(bayes_search_balanced.cv_results_)\n",
        "best_idx_balanced = bayes_search_balanced.best_index_\n",
        "train_score_balanced = cv_results_balanced.loc[best_idx_balanced, 'mean_train_score']\n",
        "test_score_balanced = cv_results_balanced.loc[best_idx_balanced, 'mean_test_score']\n",
        "gap_balanced = train_score_balanced - test_score_balanced\n",
        "\n",
        "if gap_balanced < 0.05:\n",
        "    print(\"C bon\")\n",
        "elif gap_balanced < 0.10:\n",
        "    print(\"Rsique d'overfitting\")\n",
        "else:\n",
        "    print(\"Overfitting\")\n",
        "\n",
        "\n",
        "model_custom = LogisticRegression(\n",
        "    random_state=42,\n",
        "    warm_start=True,\n",
        "    class_weight=class_weight_custom\n",
        ")\n",
        "\n",
        "bayes_search_custom = BayesSearchCV(\n",
        "    estimator=model_custom,\n",
        "    search_spaces=search_spaces_binary,\n",
        "    n_iter=30,\n",
        "    cv=cv_strategy,\n",
        "    scoring=cost_scorer,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=0,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "bayes_search_custom.fit(X_train_final, y_train_binary)\n",
        "\n",
        "cv_results_custom = pd.DataFrame(bayes_search_custom.cv_results_)\n",
        "best_idx_custom = bayes_search_custom.best_index_\n",
        "train_score_custom = cv_results_custom.loc[best_idx_custom, 'mean_train_score']\n",
        "test_score_custom = cv_results_custom.loc[best_idx_custom, 'mean_test_score']\n",
        "gap_custom = train_score_custom - test_score_custom\n",
        "\n",
        "print(f\"   Gap Train-CV: {gap_custom:.4f}\", end=\"\")\n",
        "if gap_custom < 0.05:\n",
        "    print(\"C bon\")\n",
        "elif gap_custom < 0.10:\n",
        "    print(\"Overfitting\")\n",
        "else:\n",
        "    print(\"Overfitting\")\n",
        "\n",
        "\n",
        "models_comparison = {\n",
        "    'balanced': {\n",
        "        'model': bayes_search_balanced,\n",
        "        'score': bayes_search_balanced.best_score_,\n",
        "        'gap': gap_balanced\n",
        "    },\n",
        "    'custom': {\n",
        "        'model': bayes_search_custom,\n",
        "        'score': bayes_search_custom.best_score_,\n",
        "        'gap': gap_custom\n",
        "    }\n",
        "}\n",
        "\n",
        "best_choice = None\n",
        "best_score_val = -np.inf\n",
        "\n",
        "for name, info in models_comparison.items():\n",
        "    adjusted_score = info['score'] - (info['gap'] * 2)\n",
        "    if adjusted_score > best_score_val:\n",
        "        best_score_val = adjusted_score\n",
        "        best_choice = name\n",
        "\n",
        "weight_type = best_choice\n",
        "bayes_search_binary = models_comparison[best_choice]['model']\n",
        "\n",
        "print(f\"\\n Meilleur modèle: class_weight='{weight_type}'\")\n",
        "print(f\" Meilleur score (CV): {bayes_search_binary.best_score_:.4f}\")\n",
        "print(f\" Gap Train-CV: {models_comparison[best_choice]['gap']:.4f}\")\n",
        "print(f\"\\n Meilleurs hyperparamètres:\")\n",
        "for param, value in bayes_search_binary.best_params_.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "best_model_binary = bayes_search_binary.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "y_pred_proba_binary = best_model_binary.predict_proba(X_test_final)[:, 1]\n",
        "\n",
        "thresholds_to_test = np.arange(0.20, 0.80, 0.05)\n",
        "results = []\n",
        "\n",
        "for threshold in thresholds_to_test:\n",
        "    y_pred_threshold = (y_pred_proba_binary >= threshold).astype(int)\n",
        "\n",
        "    cm = confusion_matrix(y_test_binary, y_pred_threshold)\n",
        "    if cm.shape == (2, 2):\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "\n",
        "    total_cost = fn * cost_fn + fp * cost_fp\n",
        "\n",
        "    results.append({\n",
        "        'Seuil': threshold,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1': f1,\n",
        "        'TP': tp,\n",
        "        'FP': fp,\n",
        "        'FN': fn,\n",
        "        'TN': tn,\n",
        "        'Coût_Total': total_cost\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "top_results = results_df.nsmallest(10, 'Coût_Total')\n",
        "print(top_results[['Seuil', 'Recall', 'Precision', 'F1', 'Coût_Total']].to_string(index=False))\n",
        "\n",
        "best_threshold_idx = results_df['Coût_Total'].idxmin()\n",
        "best_threshold = results_df.loc[best_threshold_idx, 'Seuil']\n",
        "\n",
        "print(f\"\\n Meilleur seuil (coût minimal): {best_threshold:.2f}\")\n",
        "print(f\"   Coût total: {results_df.loc[best_threshold_idx, 'Coût_Total']:.0f}\")\n",
        "print(f\"   Recall: {results_df.loc[best_threshold_idx, 'Recall']:.2%}\")\n",
        "print(f\"   Precision: {results_df.loc[best_threshold_idx, 'Precision']:.2%}\")\n",
        "print(f\"   F1-Score: {results_df.loc[best_threshold_idx, 'F1']:.2%}\")\n",
        "\n",
        "y_pred_binary_final = (y_pred_proba_binary >= best_threshold).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(18, 12))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "cm = confusion_matrix(y_test_binary, y_pred_binary_final)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['SOUTENABLE', 'À RISQUE'],\n",
        "            yticklabels=['SOUTENABLE', 'À RISQUE'],\n",
        "            ax=ax1, cbar_kws={'label': 'Count'})\n",
        "ax1.set_xlabel('Prédictions', fontsize=11, fontweight='bold')\n",
        "ax1.set_ylabel('Vraies valeurs', fontsize=11, fontweight='bold')\n",
        "ax1.set_title(f'Matrice de Confusion (seuil={best_threshold:.2f})',\n",
        "              fontsize=12, fontweight='bold')\n",
        "\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "fpr, tpr, thresholds_roc = roc_curve(y_test_binary, y_pred_proba_binary)\n",
        "roc_auc = roc_auc_score(y_test_binary, y_pred_proba_binary)\n",
        "\n",
        "ax2.plot(fpr, tpr, color='#e74c3c', lw=2.5, label=f'ROC (AUC = {roc_auc:.3f})')\n",
        "ax2.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance')\n",
        "\n",
        "idx_threshold = np.argmin(np.abs(thresholds_roc - best_threshold))\n",
        "ax2.scatter([fpr[idx_threshold]], [tpr[idx_threshold]],\n",
        "           color='red', s=100, zorder=5, label=f'Seuil optimal ({best_threshold:.2f})')\n",
        "ax2.set_xlabel('Taux de Faux Positifs', fontsize=11)\n",
        "ax2.set_ylabel('Taux de Vrais Positifs', fontsize=11)\n",
        "ax2.set_title('Courbe ROC', fontsize=12, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "ax3 = fig.add_subplot(gs[0, 2])\n",
        "precision_curve, recall_curve, _ = precision_recall_curve(y_test_binary, y_pred_proba_binary)\n",
        "\n",
        "ax3.plot(recall_curve, precision_curve, color='#2ecc71', lw=2.5)\n",
        "ax3.axvline(x=results_df.loc[best_threshold_idx, 'Recall'],\n",
        "           color='red', linestyle='--', lw=2, label=f'Seuil optimal ({best_threshold:.2f})')\n",
        "ax3.set_xlabel('Recall', fontsize=11)\n",
        "ax3.set_ylabel('Precision', fontsize=11)\n",
        "ax3.set_title('Courbe Precision-Recall', fontsize=12, fontweight='bold')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "ax4 = fig.add_subplot(gs[1, :])\n",
        "ax4.plot(results_df['Seuil'], results_df['Recall'], 'o-',\n",
        "         label='Recall', lw=2, markersize=6, color='#3498db')\n",
        "ax4.plot(results_df['Seuil'], results_df['Precision'], 's-',\n",
        "         label='Precision', lw=2, markersize=6, color='#e74c3c')\n",
        "ax4.plot(results_df['Seuil'], results_df['F1'], '^-',\n",
        "         label='F1-score', lw=2, markersize=6, color='#2ecc71')\n",
        "ax4.axvline(x=best_threshold, color='red', linestyle='--',\n",
        "           label=f'Seuil optimal', lw=2.5)\n",
        "ax4.set_xlabel('Seuil de décision', fontsize=11)\n",
        "ax4.set_ylabel('Score', fontsize=11)\n",
        "ax4.set_title('Métriques selon le seuil', fontsize=12, fontweight='bold')\n",
        "ax4.legend(loc='best', ncol=4)\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "ax5 = fig.add_subplot(gs[2, 0])\n",
        "ax5.plot(results_df['Seuil'], results_df['Coût_Total'], 'o-',\n",
        "         lw=2.5, markersize=7, color='#e67e22')\n",
        "ax5.axvline(x=best_threshold, color='red', linestyle='--', lw=2.5)\n",
        "ax5.scatter([best_threshold], [results_df.loc[best_threshold_idx, 'Coût_Total']],\n",
        "           color='red', s=200, zorder=5, edgecolors='black', linewidths=2)\n",
        "ax5.set_xlabel('Seuil de décision', fontsize=11)\n",
        "ax5.set_ylabel('Coût Total', fontsize=11)\n",
        "ax5.set_title('Coût Total vs Seuil', fontsize=12, fontweight='bold')\n",
        "ax5.grid(True, alpha=0.3)\n",
        "\n",
        "ax6 = fig.add_subplot(gs[2, 1])\n",
        "ax6.hist(y_pred_proba_binary[y_test_binary == 0], bins=30, alpha=0.6,\n",
        "         label='SOUTENABLE', color='#3498db', edgecolor='black')\n",
        "ax6.hist(y_pred_proba_binary[y_test_binary == 1], bins=30, alpha=0.6,\n",
        "         label='À RISQUE', color='#e74c3c', edgecolor='black')\n",
        "ax6.axvline(x=best_threshold, color='red', linestyle='--', lw=2.5,\n",
        "           label=f'Seuil ({best_threshold:.2f})')\n",
        "ax6.set_xlabel('Probabilité prédite', fontsize=11)\n",
        "ax6.set_ylabel('Fréquence', fontsize=11)\n",
        "ax6.set_title('Distribution des Probabilités', fontsize=12, fontweight='bold')\n",
        "ax6.legend()\n",
        "ax6.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "ax7 = fig.add_subplot(gs[2, 2])\n",
        "coef_binary = best_model_binary.coef_[0]\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train_final.columns,\n",
        "    'Coefficient': coef_binary,\n",
        "    'Abs_Coefficient': np.abs(coef_binary)\n",
        "}).sort_values('Abs_Coefficient', ascending=True)\n",
        "\n",
        "colors_bar = ['red' if x < 0 else 'green' for x in feature_importance['Coefficient']]\n",
        "ax7.barh(feature_importance['Feature'], feature_importance['Coefficient'],\n",
        "        color=colors_bar, alpha=0.7, edgecolor='black')\n",
        "ax7.set_xlabel('Coefficient', fontsize=11, fontweight='bold')\n",
        "ax7.set_title('Importance des Features', fontsize=12, fontweight='bold')\n",
        "ax7.axvline(x=0, color='black', linestyle='-', linewidth=1.5)\n",
        "ax7.grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.suptitle(f'Analyse Complète - Modèle Binaire ({weight_type})',\n",
        "             fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(f\"\\n Performance avec seuil optimal ({best_threshold:.2f}):\")\n",
        "print(classification_report(y_test_binary, y_pred_binary_final,\n",
        "                           target_names=['SOUTENABLE', 'À RISQUE'], digits=4))\n",
        "\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test_binary, y_pred_binary_final).ravel()\n",
        "print(f\"Vrais Positifs (À RISQUE bien détecté): {tp}\")\n",
        "print(f\"Faux Négatifs (À RISQUE raté): {fn} → Coût = {fn * cost_fn}\")\n",
        "print(f\"Faux Positifs (Fausse alerte): {fp} → Coût = {fp * cost_fp}\")\n",
        "print(f\"Vrais Négatifs (SOUTENABLE bien détecté): {tn}\")\n",
        "print(f\"\\n COÛT TOTAL: {fn * cost_fn + fp * cost_fp}\")\n",
        "\n",
        "print(f\"\\n COMPARAISON DES STRATÉGIES:\")\n",
        "print(f\"Stratégie 'balanced':\")\n",
        "print(f\"Score CV: {bayes_search_balanced.best_score_:.4f}\")\n",
        "print(f\"Gap: {gap_balanced:.4f}\")\n",
        "print(f\"Stratégie 'custom weights':\")\n",
        "print(f\"Score CV: {bayes_search_custom.best_score_:.4f}\")\n",
        "print(f\"Gap: {gap_custom:.4f}\")\n",
        "print(f\"\\n Stratégie retenue: {weight_type}\")\n",
        "\n",
        "feature_importance_sorted = feature_importance.sort_values('Abs_Coefficient', ascending=False)\n",
        "print(feature_importance_sorted[['Feature', 'Coefficient']].to_string(index=False))"
      ],
      "metadata": {
        "id": "B0o3ImSDuPlG"
      },
      "execution_count": null,
      "outputs": [],
      "id": "B0o3ImSDuPlG"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}