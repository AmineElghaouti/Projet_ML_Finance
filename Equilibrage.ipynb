{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Equilibrage des données***\n"
      ],
      "metadata": {
        "id": "9H2TUlswy241"
      },
      "id": "9H2TUlswy241"
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Pour option 1***"
      ],
      "metadata": {
        "id": "iNotuji0dp4Y"
      },
      "id": "iNotuji0dp4Y"
    },
    {
      "cell_type": "code",
      "source": [
        "df_balanced1 = data_clean.copy()\n",
        "\n",
        "label_encoder1 = LabelEncoder()\n",
        "df_balanced1['Risk_encoded'] = label_encoder1.fit_transform(df_balanced1['Risk'])\n",
        "\n",
        "feature_cols = ['External_Debt_GDP', 'Debt_Service_Exports','GDP_Growth',\n",
        "                'Current_Account', 'Exchange_Rate',\n",
        "                'Corruption_Governance', 'Net_ODA_received']\n",
        "\n",
        "train_mask1 = df_balanced1['Year'] <= 2021\n",
        "test_mask1 = df_balanced1['Year'] > 2021\n",
        "\n",
        "X_train_raw1 = df_balanced1.loc[train_mask1, feature_cols]\n",
        "y_train1 = df_balanced1.loc[train_mask1, 'Risk_encoded']\n",
        "\n",
        "X_test_raw1 = df_balanced1.loc[test_mask1, feature_cols]\n",
        "y_test1 = df_balanced1.loc[test_mask1, 'Risk_encoded']\n",
        "\n",
        "\n",
        "scaler1 = StandardScaler()\n",
        "X_train_scaled1 = scaler1.fit_transform(X_train_raw1)\n",
        "X_test_scaled1 = scaler1.transform(X_test_raw1)\n",
        "\n",
        "X_train_scaled1 = pd.DataFrame(X_train_scaled1, columns=feature_cols, index=X_train_raw1.index)\n",
        "X_test_scaled1 = pd.DataFrame(X_test_scaled1, columns=feature_cols, index=X_test_raw1.index)\n",
        "\n",
        "\n",
        "class_counts1 = Counter(y_train1)\n",
        "max_count1 = max(class_counts1.values())\n",
        "target_minority1 = max_count1 // 2  # Ratio 1:2\n",
        "\n",
        "sampling_strategy_dict1 = {}\n",
        "for class_label, count in class_counts1.items():\n",
        "    if count < target_minority1:\n",
        "        sampling_strategy_dict1[class_label] = target_minority1\n",
        "\n",
        "print(f\"Distribution originale Train : {class_counts1}\")\n",
        "print(f\"Cible pour les minoritaires : {target_minority1}\")\n",
        "\n",
        "distress_code = label_encoder1.transform(['DISTRESS'])[0] if 'DISTRESS' in label_encoder1.classes_ else -1\n",
        "if distress_code != -1:\n",
        "    n_distress = class_counts1[distress_code]\n",
        "    k = min(5, n_distress - 1)\n",
        "else:\n",
        "    k = 5\n",
        "\n",
        "smote_enn1 = SMOTEENN(\n",
        "    sampling_strategy=sampling_strategy_dict1,\n",
        "    smote=SMOTE(k_neighbors=k, random_state=42),\n",
        "    enn=EditedNearestNeighbours(sampling_strategy='all'),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"\\nApplication de SMOTEENN en cours...\")\n",
        "X_train_resampled1, y_train_resampled1 = smote_enn1.fit_resample(X_train_scaled1, y_train1)\n",
        "\n",
        "print(f\"Nouvelle distribution Train : {Counter(y_train_resampled1)}\")\n",
        "\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "classes_present1 = np.unique(y_train_resampled1)\n",
        "weights1 = compute_class_weight(class_weight='balanced', classes=classes_present1, y=y_train_resampled1)\n",
        "class_weight_dict1 = dict(zip(classes_present1, weights1))\n",
        "\n",
        "print(\"\\nPoids résiduels (à passer au modèle) :\")\n",
        "for cls, w in class_weight_dict1.items():\n",
        "    print(f\"Classe {label_encoder1.inverse_transform([cls])[0]} : {w:.2f}\")\n",
        "\n",
        "\n",
        "X_train_final = pd.DataFrame(X_train_resampled1, columns=feature_cols)\n",
        "y_train_final = y_train_resampled1\n",
        "X_test_final = pd.DataFrame(X_test_scaled1, columns=feature_cols)\n",
        "y_test_final = y_test1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI_pJ_ERcJ8O",
        "outputId": "711a7f91-91ae-4c00-d1f8-02b94ac51fdb"
      },
      "id": "GI_pJ_ERcJ8O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution originale Train : Counter({3: 198, 2: 128, 1: 122, 0: 35})\n",
            "Cible pour les minoritaires : 99\n",
            "\n",
            "Application de SMOTEENN en cours...\n",
            "Nouvelle distribution Train : Counter({0: 184, 2: 141, 1: 129, 3: 69})\n",
            "\n",
            "Poids résiduels (à passer au modèle) :\n",
            "Classe DISTRESS : 0.71\n",
            "Classe HIGH : 1.01\n",
            "Classe LOW : 0.93\n",
            "Classe MODERATE : 1.89\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}